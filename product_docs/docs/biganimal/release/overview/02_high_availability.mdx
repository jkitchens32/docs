---
title: "Supported architectures"
redirects:
  - 02_high_availibility
---

BigAnimal supports three deployment architectures: 
- Single node
- Standard high availability
- Extreme high availability (beta)

You choose which type of deployment you want when creating your cluster on the [Create Cluster](https://portal.biganimal.com/create-cluster) page in the [BigAnimal](https://portal.biganimal.com) portal.    

## Extreme high availability

Extreme high availability clusters are built with EDB Postgres Distributed, a logical replication tool that delivers more advanced cluster management compared to a physical replication based system. The primary component of EDB Postgres Distributed is Bi-Directional Replication (BDR). BDR is a PostgreSQL extension providing multi-master replication and data distribution with advanced conflict management, data-loss protection, and throughput up to 5X faster than native logical replication, and enables distributed PostgreSQL clusters with high availability up to five 9s. Extreme high availability clusters use EDB Postgres Extended Server as the database type. EDB Postgres Extended Server is fully compatible with community PostgreSQL. 

The extreme high availability clusters are all in one cloud region with three availability zones. One BDR group is the *leader* node. It exists in one availability zone along with a shadow node. In another availability zone, there are two more *shadow* nodes. A third availability zone contains a witness node. The leader node represents the entire cluster or a local region. The shadow nodes wait to take over when needed. If a node loses contact, BigAnimal switches immediately to a shadow node to continue processing. The witness node [NEED DEFINITION OF WHAT ROLE THE WITNESS NODE PLAYS]. This architecture allows for higher performance and faster failover recovery compared to standard high availability.  

![*BigAnimal Cluster4*](images/extreme-availability-ui.png)

EDB Postgres Distributed uses a [Raft](https://raft.github.io/)-based consensus architecture. While regular database operations (INSERT, SELECT, DELETE) don’t require cluster-wide consensus, the extreme high availability architecture benefits from an odd number of BDR nodes to make decisions that require consensus, such as generating new global sequences, or distributed DDL operations.  

## Standard high availability

The high availability option is provided to minimize downtime in cases of failures. High-availability clusters—one *primary* and two *replicas*—are configured automatically, with replicas staying up to date through physical streaming replication. In cloud regions with availability zones, clusters are provisioned across multiple availability zones to provide fault tolerance in the face of a datacenter failure.

-   Replicas are usually called *standby servers*. 
-   In case of temporary or permanent unavailability of the primary, a standby replica becomes the primary.

![*BigAnimal Cluster4*](images/high-availability-ui.png)

Incoming client connections are always routed to the current primary. In case of failure of the primary, a standby replica is automatically promoted to primary, and new connections are routed to the new primary. When the old primary recovers, it rejoins the cluster as a replica.

By default, replication is synchronous to one replica and asynchronous to the other. That is, one replica must confirm that a transaction record was written to disk before the client receives acknowledgment of a successful commit. In PostgreSQL terms, `synchronous_commit` is set to `on` and `synchronous_standby_names` is set to `ANY 1 (replica-1, replica-2)`. You can modify this behavior on a per-transaction, per-session, per-user, or per-database basis with appropriate `SET` or `ALTER` commands.

## Single node

For nonproduction use cases where high availability is not a primary concern, a cluster deployment with high availability not enabled provides one primary with no standby servers for failover or read-only workloads. 

In case of permanent unavailability of the primary, a restore from a backup is required. 

![*BigAnimal Cluster4*](images/ha-not-enabled-UI.png)
